,Lens ID,Title,Publication Year,Publication Type,Source Title,Publisher,Source Country,Author/s,Abstract,Fields of Study,Keywords,MeSH Terms,DOI,Is Open Access,Lang,Category
2,001-046-496-996-745,An Exploratory Assessment of a Multidimensional Healthcare and Economic Data on COVID-19 in Nigeria.,2020,journal article,Data in brief,Elsevier BV,Netherlands,Ezekiel Ogundepo; Sakinat Oluwabukonla Folorunso; Olubayo Adekanmbi; Olalekan Akinsande; Oluwatobi Banjo; Emeka Ogbuju; Francisca Oladipo; Olawale Victor Abimbola; Ehizokhale Oseghale; Oluwatobi Babajide,"The coronavirus disease of 2019 (COVID-19) is a pandemic that is ravaging Nigeria and the world at large. This data article provides a dataset of daily updates of COVID-19 as reported online by the Nigeria Centre for Disease Control (NCDC) from February 27, 2020 to September 29, 2020. The data were obtained through web scraping from different sources and it includes some economic variables such as the Nigeria budget for each state in 2020, population estimate, healthcare facilities, and the COVID-19 laboratories in Nigeria. The dataset has been processed using the standard of the FAIR data principle which encourages its findability, accessibility, interoperability, and reusability and will be relevant to researchers in different fields such as Data Science, Epidemiology, Earth Modelling, and Health Informatics.",Health informatics; Health care; Findability; Interoperability; Geography; Data science; Economic data; Web scraping; Population; Pandemic,COVID-19 cases per state; COVID-19 laboratories; Economy; Healthcare facilities; NCDC tweets; Nigeria states budget; Population; Time series,,10.1016/j.dib.2020.106424,True,en,FAIRification of data
31,008-165-777-582-81X,Making radiotherapy more efficient with FAIR data,2021,journal article,Physica medica : PM : an international journal devoted to the applications of physics to medicine and biology : official journal of the Italian Association of Biomedical Physics (AIFB),Associazione Italiana di Fisica Medica,Italy,Petros Kalendralis; Matthijs Sloep; Johan van Soest; Andre Dekker; Rianne Fijten,"Given the rapid growth of artificial intelligence (AI) applications in radiotherapy and the related transformations toward the data-driven healthcare domain, this article summarizes the need and usage of the FAIR (Findable, Accessible, Interoperable, Reusable) data principles in radiotherapy. This work introduces the FAIR data concept, presents practical and relevant use cases and the future role of the different parties involved. The goal of this article is to provide guidance and potential applications of FAIR to various radiotherapy stakeholders, focusing on the central role of medical physicists.",Health care; Domain (software engineering); Work (electrical); Interoperability; Data science; Medical physicist; Use case; Computer science,Artificial intelligence; FAIR data; Radiotherapy,Artificial Intelligence,10.1016/j.ejmp.2021.01.083,True,en,Overview and Adoption of FAIR Principles
36,008-576-734-483-121,Multi-Institutional Breast Cancer Detection Using a Secure On-Boarding Service for Distributed Analytics,2022,journal article,Applied Sciences,MDPI AG,,Sascha Welten; Lars Hempel; Masoud Abedi; Yongli Mou; Mehrshad Jaberansary; Laurenz Neumann; Sven Weber; Kais Tahar; Yeliz Ucer Yediel; Matthias Löbe; Stefan Decker; Oya Beyan; Toralf Kirsten,"<jats:p>The constant upward movement of data-driven medicine as a valuable option to enhance daily clinical practice has brought new challenges for data analysts to get access to valuable but sensitive data due to privacy considerations. One solution for most of these challenges are Distributed Analytics (DA) infrastructures, which are technologies fostering collaborations between healthcare institutions by establishing a privacy-preserving network for data sharing. However, in order to participate in such a network, a lot of technical and administrative prerequisites have to be made, which could pose bottlenecks and new obstacles for non-technical personnel during their deployment. We have identified three major problems in the current state-of-the-art. Namely, the missing compliance with FAIR data principles, the automation of processes, and the installation. In this work, we present a seamless on-boarding workflow based on a DA reference architecture for data sharing institutions to address these problems. The on-boarding service manages all technical configurations and necessities to reduce the deployment time. Our aim is to use well-established and conventional technologies to gain acceptance through enhanced ease of use. We evaluate our development with six institutions across Germany by conducting a DA study with open-source breast cancer data, which represents the second contribution of this work. We find that our on-boarding solution lowers technical barriers and efficiently deploys all necessary components and is, therefore, indeed an enabler for collaborative data sharing.</jats:p>",Workflow; Software deployment; Enabling; Computer science; Analytics; Data sharing; Cloud computing; Service (business); Computer security; Data science; Knowledge management; Business; Database; Software engineering; Medicine; Psychology; Alternative medicine; Pathology; Marketing; Psychotherapist; Operating system,,,10.3390/app12094336,True,en,Infrastructure and Tools
44,009-986-519-168-493,Implementation of a clinical trial recruitment support system based on fast healthcare interoperability resources (FHIR) in a cardiology department,2022,journal article,European Heart Journal,Oxford University Press (OUP),United Kingdom,C Scherer; S Endres; M Orban; S Kaeaeb; S Massberg; A Winter; M Loebe,"<jats:title>Abstract</jats:title>;                <jats:sec>;                   <jats:title>Background</jats:title>;                   <jats:p>Clinical Trial Recruitment Support Systems can booster patient inclusion of clinical trials by automatically analyzing eligibility criteria based on electronic health records. However, missing interoperability has hindered introduction of those systems on a broader scale.</jats:p>;                </jats:sec>;                <jats:sec>;                   <jats:title>Purpose</jats:title>;                   <jats:p>Our aim was to develop a recruitment support system based on FHIR R4 and evaluate its usage and features in a cardiology department.</jats:p>;                </jats:sec>;                <jats:sec>;                   <jats:title>Methods/Implementation</jats:title>;                   <jats:p>Clinical conditions, anamnesis, examinations, allergies, medication, laboratory data and echocardiography results were imported as FHIR resources. Trial study nurses and physicians were enabled to add new and edit trial information and input inclusion and exclusion criteria using a web-browser user interface in the hospital intranet. All information were recorded on the server side as the FHIR resources “ResearchStudy” and “Group”. Eligibility criteria linked by the logical operation “OR” were represented by using multiple FHIR Group resources for enrollment. On the client side, eligibility criteria were transformed to a tree-like structure (see Figure 1). Upon user demand, all hospitalized and ambulatory patients in the cardiology department were instantly screened for trial eligibility using the FHIR eligibility criteria on the existing patients' FHIR resources. Furthermore, study personal was able to manually edit trial status (i.e. ineligible, on-study, ...) of patients, which was implemented using the FHIR resource “ResearchSubject”.</jats:p>;                </jats:sec>;                <jats:sec>;                   <jats:title>Results</jats:title>;                   <jats:p>This implementation of a CTRSS based on FHIR R4 was evaluated in clinical practice: Beginning from 1st April 2021 the application was used as an additional patient screening tool for the four trials CLOSURE-AF, FAIR-HF2, SPRIRIT-HF and TORCH-PLUS of the German Centre for Cardiovascular Research. As the COVID-19 pandemic is prohibiting any proper comparison of patient inclusion rates, efficacy of the recruitment support system was tested by comparing the numbers of patients identified by the recruitment support system and enrolled in a trial to the actual number of enrolled patients irrespective of the screening method from 1st April 2021 to 23rd November 2021. The system was able to identify 52 of 55 patients included in those four clinical trials.</jats:p>;                </jats:sec>;                <jats:sec>;                   <jats:title>Conclusion</jats:title>;                   <jats:p>Use of FHIR for defining eligibility criteria of clinical trials may facilitate interoperability and allow automatic screening for eligible patients at multiple sites of different healthcare providers in the future. Upcoming changes in FHIR should allow easier description of “OR”-linked eligibility criteria.</jats:p>;                </jats:sec>;                <jats:sec>;                   <jats:title>Funding Acknowledgement</jats:title>;                   <jats:p>Type of funding sources: Public grant(s) – National budget only. Main funding source(s): Deutsche Forschungsgemeinschaft</jats:p>;                </jats:sec>",Medicine; Clinical trial; Intranet; Interoperability; Medical emergency; Health care; Inclusion and exclusion criteria; The Internet; World Wide Web; Internal medicine; Computer science; Alternative medicine; Pathology; Economics; Economic growth,,,10.1093/eurheartj/ehac544.2795,True,en,Infrastructure and Tools
69,014-359-517-534-478,"Registries, Databases and Repositories for Developing Artificial Intelligence in Cancer Care.",2021,journal article,Clinical oncology (Royal College of Radiologists (Great Britain)),W.B. Saunders Ltd,United Kingdom,J W Wang; M Williams,"Modern artificial intelligence techniques have solved some previously intractable problems and produced impressive results in selected medical domains. One of their drawbacks is that they often need very large amounts of data. Pre-existing datasets in the form of national cancer registries, image/genetic depositories and clinical datasets already exist and have been used for research. In theory, the combination of healthcare Big Data with modern, data-hungry artificial intelligence techniques should offer significant opportunities for artificial intelligence development, but this has not yet happened. Here we discuss some of the structural reasons for this, barriers preventing artificial intelligence from making full use of existing datasets, and make suggestions as to enable progress. To do this, we use the framework of the 6Vs of Big Data and the FAIR criteria for data sharing and availability (Findability, Accessibility, Interoperability, and Reuse). We share our experience in navigating these barriers through The Brain Tumour Data Accelerator, a Brain Tumour Charity-supported initiative to integrate fragmented patient data into an enriched dataset. We conclude with some comments as to the limits of such approaches.",Interoperability; Reuse; Big data; Data sharing; Computer science; Health care; Medicine; Data science; Artificial intelligence; World Wide Web; Data mining; Ecology; Alternative medicine; Pathology; Economics; Biology; Economic growth,Artificial intelligence; Big Data; database; deep learning; registries; repository,"Artificial Intelligence; Big Data; Databases, Factual; Humans; Neoplasms/therapy; Registries",10.1016/j.clon.2021.11.040,False,en,Overview and Adoption of FAIR Principles
87,018-013-878-593-761,"A Data Transformation Methodology to Create Findable, Accessible, Interoperable, and Reusable Health Data: Software Design, Development, and Evaluation Study.",2023,journal article,Journal of medical Internet research,JMIR Publications Inc.,Canada,A Anil Sinaci; Mert Gencturk; Huseyin Alper Teoman; Gokce Banu Laleci Erturkmen; Celia Alvarez-Romero; Alicia Martinez-Garcia; Beatriz Poblador-Plou; Jonás Carmona-Pírez; Matthias Löbe; Carlos Luis Parra-Calderon,"<AbstractText Label=""BACKGROUND"">Sharing health data is challenging because of several technical, ethical, and regulatory issues. The Findable, Accessible, Interoperable, and Reusable (FAIR) guiding principles have been conceptualized to enable data interoperability. Many studies provide implementation guidelines, assessment metrics, and software to achieve FAIR-compliant data, especially for health data sets. Health Level 7 (HL7) Fast Healthcare Interoperability Resources (FHIR) is a health data content modeling and exchange standard.</AbstractText>;           <AbstractText Label=""OBJECTIVE"">Our goal was to devise a new methodology to extract, transform, and load existing health data sets into HL7 FHIR repositories in line with FAIR principles, develop a Data Curation Tool to implement the methodology, and evaluate it on health data sets from 2 different but complementary institutions. We aimed to increase the level of compliance with FAIR principles of existing health data sets through standardization and facilitate health data sharing by eliminating the associated technical barriers.</AbstractText>;           <AbstractText Label=""METHODS"">Our approach automatically processes the capabilities of a given FHIR end point and directs the user while configuring mappings according to the rules enforced by FHIR profile definitions. Code system mappings can be configured for terminology translations through automatic use of FHIR resources. The validity of the created FHIR resources can be automatically checked, and the software does not allow invalid resources to be persisted. At each stage of our data transformation methodology, we used particular FHIR-based techniques so that the resulting data set could be evaluated as FAIR. We performed a data-centric evaluation of our methodology on health data sets from 2 different institutions.</AbstractText>;           <AbstractText Label=""RESULTS"">Through an intuitive graphical user interface, users are prompted to configure the mappings into FHIR resource types with respect to the restrictions of selected profiles. Once the mappings are developed, our approach can syntactically and semantically transform existing health data sets into HL7 FHIR without loss of data utility according to our privacy-concerned criteria. In addition to the mapped resource types, behind the scenes, we create additional FHIR resources to satisfy several FAIR criteria. According to the data maturity indicators and evaluation methods of the FAIR Data Maturity Model, we achieved the maximum level (level 5) for being Findable, Accessible, and Interoperable and level 3 for being Reusable.</AbstractText>;           <AbstractText Label=""CONCLUSIONS"">We developed and extensively evaluated our data transformation approach to unlock the value of existing health data residing in disparate data silos to make them available for sharing according to the FAIR principles. We showed that our method can successfully transform existing health data sets into HL7 FHIR without loss of data utility, and the result is FAIR in terms of the FAIR Data Maturity Model. We support institutional migration to HL7 FHIR, which not only leads to FAIR data sharing but also eases the integration with different research networks.</AbstractText>;           <CopyrightInformation>©A Anil Sinaci, Mert Gencturk, Huseyin Alper Teoman, Gokce Banu Laleci Erturkmen, Celia Alvarez-Romero, Alicia Martinez-Garcia, Beatriz Poblador-Plou, Jonás Carmona-Pírez, Matthias Löbe, Carlos Luis Parra-Calderon. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 08.03.2023.</CopyrightInformation>",,FAIR principles; Findable  Accessible  Interoperable  and Reusable principles; HL7 FHIR; Health Level 7 Fast Healthcare Interoperability Resources; health data sharing; health data transformation; secondary use,Humans; Electronic Health Records; Software Design; Software; Health Level Seven; Information Dissemination,10.2196/42822,True,en,Infrastructure and Tools
124,027-288-721-002-272,Term sets: A transparent and reproducible representation of clinical code sets.,2019,journal article,PloS one,Public Library of Science (PLoS),United States,Richard Williams; Benjamin Brown; Evan Kontopantelis; Tjeerd van Staa; Niels Peek,"Objective ; Clinical code sets are vital to research using routinely-collected electronic healthcare data. Existing code set engineering methods pose significant limitations when considering reproducible research. To improve the transparency and reusability of research, these code sets must abide by FAIR principles; this is not currently happening. We propose ‘term sets’, an equivalent alternative to code sets that are findable, accessible, interoperable and reusable.; ; ; Materials and methods ; We describe a new code set representation, consisting of natural language inclusion and exclusion terms (term sets), and explain its relationship to code sets. We formally prove that any code set has a corresponding term set. We demonstrate utility by searching for recently published code sets, representing them as term sets, and reporting on the number of inclusion and exclusion terms compared with the size of the code set.; ; ; Results ; Thirty-one code sets from 20 papers covering diverse disease domains were converted into term sets. The term sets were on average 74% the size of their equivalent original code set. Four term sets were larger due to deficiencies in the original code sets.; ; ; Discussion ; Term sets can concisely represent any code set. This may reduce barriers for examining and reusing code sets, which may accelerate research using healthcare databases. We have developed open-source software that supports researchers using term sets.; ; ; Conclusion ; Term sets are independent of clinical code terminologies and therefore: enable reproducible research; are resistant to terminology changes; and are less error-prone as they are shorter than the equivalent code set.",Set (abstract data type); Natural language; Code (set theory); Software; Computer science; Representation (mathematics); Term (time); Theoretical computer science; Transparency (human–computer interaction),,"Clinical Coding; Databases, Factual; Electronic Health Records; Software",10.1371/journal.pone.0212291,True,en,FAIRification of data
128,028-004-546-589-369,Maximizing data value for biopharma through FAIR and quality implementation: FAIR plus Q.,2022,journal article,Drug discovery today,Elsevier BV,Netherlands,Ian Harrow; Rama Balakrishnan; Hande Küçük McGinty; Tom Plasterer; Martin Romacker,"Over recent years, there has been exciting growth in collaboration between academia and industry in the life sciences to make data more Findable, Accessible, Interoperable and Reusable (FAIR) to achieve greater value. Despite considerable progress, the transformative shift from an application-centric to a data-centric perspective, enabled by FAIR implementation, remains very much a work in progress on the 'FAIR journey'. In this review, we consider use cases for FAIR implementation. These can be deployed alongside assessment of data quality to maximize the value of data generated from research, clinical trials, and real-world healthcare data, which are essential for the discovery and development of new medical treatments by biopharma.",Transformative learning; Interoperability; Quality (philosophy); Computer science; Data science; Data quality; Value (mathematics); Knowledge management; Business; Marketing; World Wide Web; Psychology; Pedagogy; Philosophy; Metric (unit); Epistemology; Machine learning,Data quality assessment; Data-centric culture; FAIR data; FAIR maturity indicators; FAIR use cases,Biological Science Disciplines; Data Accuracy; Industry,10.1016/j.drudis.2022.01.006,True,en,Overview and Adoption of FAIR Principles
143,030-585-314-366-166,"Insurance claims related to opioid dependence have risen by 3200%, US study finds",2016,journal article,BMJ (Clinical research ed.),BMJ,United Kingdom,Michael McCarthy,"Private health insurance claims for opioid dependence in the United States rose more than 3200% from 2007 to 2014, an analysis of privately billed healthcare claims has shown.1 The study was conducted by FAIR Health, a New York City based non-profit corporation that maintains a database of over 20 billion privately billed healthcare claims and provides healthcare cost data and analysis to government agencies, insurers, providers, and consumers.; ; The US is currently experiencing a major epidemic of opioid dependence, misuse, and deaths resulting from overdose. The US Centers for Disease Control and Prevention noted that since 1999 the number of overdose deaths from opioids, including prescription opioids and heroin, …",Government; Health care; Medical prescription; Corporation; Heroin; Opioid; Health insurance; Insurance claims; Computer security; Family medicine; Medicine,,Adolescent; Adult; Aged; Epidemics; Female; Humans; Insurance Claim Review/statistics & numerical data; Male; Middle Aged; Opioid-Related Disorders/drug therapy; Sex Distribution; United States/epidemiology; Young Adult,10.1136/bmj.i4340,False,en,Overview and Adoption of FAIR Principles
147,031-313-139-785-60X,FAIR data sharing: The roles of common data elements and harmonization.,2020,journal article,Journal of biomedical informatics,Elsevier BV,United States,Rebecca Daniels Kush; Denise Warzel; Maura A. Kush; Alexander Sherman; Eileen A. Navarro; Ronald D. Fitzmartin; Frank Pétavy; Jose Galvez; Lauren B. Becnel; F. L. Zhou; Nicole Harmon; Barbara Jauregui; Tammy Jackson; Lynn D. Hudson,"The value of robust and responsible data sharing in clinical research and healthcare is recognized by patients, patient advocacy groups, researchers, journal editors, and the healthcare industry globally. Privacy and security concerns acknowledged, the act of exchanging data (interoperability) along with its meaning (semantic interoperability) across studies and between partners has been difficult, if not elusive. For shared data to retain its value, a recommendation has been made to follow the Findable, Accessible, Interoperable, Reusable (FAIR) principles. Without applying appropriate data exchange standards with domain-relevant content standards and accessible rich metadata that uses applicable terminologies, interoperability is burdened by the need for transformation and/or mapping. These obstacles to interoperability limit the findability, accessibility and reusability of data, thus diminishing its value and making it impossible to adhere to FAIR principles. One effort to standardize data collection has been through common data elements (CDEs). CDEs are data collection units comprising one or more questions together with a set of valid values. Some CDEs contain standardized terminology concepts that define the meaning of the data, and others include links to unique terminology concept identifiers and unique identifiers for each CDE; however, usually CDEs are defined for specific projects or collaborations and lack traceable or machine readable semantics. While the name implies that these are 'common', this has not necessarily been a requirement, and many CDEs have not been commonly used. The National Institutes of Health (NIH) CDEs are, in fact, a conglomerate of CDEs developed in silos by various NIH institutes. Therefore, CDEs have not brought the anticipated benefit to the industry through widescale interoperability, nor is there widespread reuse of CDEs. Certain institutes in the NIH recommend, albeit do not enforce, institute-specific preferred CDEs; however, at the NIH level a preponderance of choice and a lack of any overarching harmonization of CDEs or consistency in linking them to controlled terminology or common identifiers create confusion for researchers in their efforts to identify the best CDEs for their protocol. The problem of comparing data among studies is exacerbated when researchers select different CDEs for the same variable or data collection field. This manuscript explores reasons for the disappointingly low adoption of CDEs and the inability of CDEs or other clinical research standards to broadly solve the interoperability and data sharing problems. Recommendations are offered for rectifying this situation to enable responsible data sharing that will help in adherence to FAIR principles and the realization of Learning Health Systems for the sake of all of us as patients.",Unique identifier; Data exchange; Learning standards; Findability; Semantic interoperability; Interoperability; Data science; Data sharing; Computer science; Metadata,,Biomedical Research; Common Data Elements; Humans; Information Dissemination; Metadata; Population Health,10.1016/j.jbi.2020.103421,True,en,Overview and Adoption of FAIR Principles
153,033-040-950-973-409,A Learning Framework for Medical Image-Based Intelligent Diagnosis from Imbalanced Datasets.,2021,journal article,Studies in health technology and informatics,IOS Press,Netherlands,Tetiana Biloborodova; Inna Skarga-Bandurova; Mark Koverha; Illia Skarha-Bandurov; Yelyzaveta Yevsieieva,"Medical image classification and diagnosis based on machine learning has made significant achievements and gradually penetrated the healthcare industry. However, medical data characteristics such as relatively small datasets for rare diseases or imbalance in class distribution for rare conditions significantly restrains their adoption and reuse. Imbalanced datasets lead to difficulties in learning and obtaining accurate predictive models. This paper follows the FAIR paradigm and proposes a technique for the alignment of class distribution, which enables improving image classification performance in imbalanced data and ensuring data reuse. The experiments on the acne disease dataset support that the proposed framework outperforms the baselines and enable to achieve up to 5% improvement in image classification.",Machine learning; Artificial intelligence; Reuse; Data reuse; Image based; Healthcare industry; Imbalanced data; Class (biology); Computer science; Contextual image classification; Class (philosophy); Image (mathematics); Data mining; Pattern recognition (psychology); Engineering; Waste management,Medical image classification; imbalanced data; machine learning oversampling,Diagnostic Imaging; Machine Learning,10.3233/shti210801,True,en,Overview and Adoption of FAIR Principles
166,035-200-796-057-420,Distributed learning on 20 000+ lung cancer patients - The Personal Health Train.,2020,journal article,Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology,Elsevier Ireland Ltd,Netherlands,Timo M. Deist; Frank J. W. M. Dankers; Priyanka Ojha; M. Scott Marshall; Tomas Janssen; Corinne Faivre-Finn; Carlotta Masciocchi; Vincenzo Valentini; Jiazhou Wang; Jiayan Chen; Zhen Zhang; Emiliano Spezi; M. Button; Joost J. Nuyttens; René M. Vernhout; Johan van Soest; Arthur Jochems; René Monshouwer; Johan Bussink; Gareth J Price; Philippe Lambin; Andre Dekker,"Background and purpose Access to healthcare data is indispensable for scientific progress and innovation. Sharing healthcare data is time-consuming and notoriously difficult due to privacy and regulatory concerns. The Personal Health Train (PHT) provides a privacy-by-design infrastructure connecting FAIR (Findable, Accessible, Interoperable, Reusable) data sources and allows distributed data analysis and machine learning. Patient data never leaves a healthcare institute. Materials and methods Lung cancer patient-specific databases (tumor staging and post-treatment survival information) of oncology departments were translated according to a FAIR data model and stored locally in a graph database. Software was installed locally to enable deployment of distributed machine learning algorithms via a central server. Algorithms (MATLAB, code and documentation publicly available) are patient privacy-preserving as only summary statistics and regression coefficients are exchanged with the central server. A logistic regression model to predict post-treatment two-year survival was trained and evaluated by receiver operating characteristic curves (ROC), root mean square prediction error (RMSE) and calibration plots. Results In 4 months, we connected databases with 23 203 patient cases across 8 healthcare institutes in 5 countries (Amsterdam, Cardiff, Maastricht, Manchester, Nijmegen, Rome, Rotterdam, Shanghai) using the PHT. Summary statistics were computed across databases. A distributed logistic regression model predicting post-treatment two-year survival was trained on 14 810 patients treated between 1978 and 2011 and validated on 8 393 patients treated between 2012 and 2015. Conclusion The PHT infrastructure demonstrably overcomes patient privacy barriers to healthcare data sharing and enables fast data analyses across multiple institutes from different countries with different regulatory regimens. This infrastructure promotes global evidence-based medicine while prioritizing patient privacy.",Software deployment; Logistic regression; Health care; Graph database; Interoperability; Data science; Computer science; Documentation; Big data; Data model,Big data; Distributed learning; FAIR data; Federated learning; Lung cancer; Machine learning; Prediction modeling; Survival analysis,Algorithms; China; Humans; Lung Neoplasms; Machine Learning; Privacy,10.1016/j.radonc.2019.11.019,True,en,Infrastructure and Tools
169,035-524-672-872-432,Road to FAIR genomes: a gap analysis of NGS data generation and sharing in the Netherlands.,2022,journal article,BMJ open science,Portico,England,Jeroen A M Belien; Anke E Kip; Morris A Swertz,"<AbstractText Label=""Objective"" NlmCategory=""UNASSIGNED"">This study investigates current standards and operational gaps in the management and sharing of next generation sequencing (NGS) data within the healthcare and research setting and according to Findable, Accessible, Interoperable and Reusable (FAIR) principles.</AbstractText>;           <AbstractText Label=""Methods"" NlmCategory=""UNASSIGNED"">The analysis was performed as the basis from which to bridge identified gaps and develop widely accepted working standards that ensure optimal reusability of genomic data in healthcare and research settings in the Netherlands. This work is part of the 'Rational Pharmacotherapy Program' led by ZonMw, The Netherlands Organisation for Health Research and Development, which aims to promote the efficient implementation of NGS and personalised medicine within Dutch healthcare, with an initial focus on oncology and rare diseases.</AbstractText>;           <AbstractText Label=""Results"" NlmCategory=""UNASSIGNED"">Based on this analysis and as part of this programme, a consortium was formed to develop an instruction manual for FAIR genomic data in clinical care and research based on an inventory of commonly used workflows and standards in the (inter)national field of genome analysis.</AbstractText>;           <AbstractText Label=""Conclusions"" NlmCategory=""UNASSIGNED"">The gap analysis presented and discussed in this paper represents the starting point for this inventory and is a possible contribution from the Netherlands to the European 1+ Million Genomes Initiative. This paper addresses the topics of data generation, data quality, (meta)data standards, data storage and archiving and data integration and exchange.</AbstractText>;           <CopyrightInformation>© Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY. Published by BMJ.</CopyrightInformation>",Interoperability; Workflow; Computer science; Data sharing; Data science; Health care; Data management; Best practice; Data exchange; World Wide Web; Data mining; Medicine; Political science; Database; Alternative medicine; Pathology; Law,informatics; translational medical research,,10.1136/bmjos-2021-100268,True,en,Overview and Adoption of FAIR Principles
187,039-075-851-664-49X,FAIR Machine Learning Model Pipeline Implementation of COVID-19 Data,2022,journal article,Data Intelligence,MIT Press,,Sakinat Folorunso; Ezekiel Ogundepo; Mariam Basajja; Joseph Awotunde; Abdullahi Kawu; Francisca Oladipo; Abdullahi Ibrahim,"<jats:title>Abstract</jats:title>;                <jats:p>Research and development are gradually becoming data-driven and the implementation of the FAIR Guidelines (that data should be Findable, Accessible, Interoperable, and Reusable) for scientific data administration and stewardship has the potential to remarkably enhance the framework for the reuse of research data. In this way, FAIR is aiding digital transformation. The ‘FAIRification’ of data increases the interoperability and (re)usability of data, so that new and robust analytical tools, such as machine learning (ML) models, can access the data to deduce meaningful insights, extract actionable information, and identify hidden patterns. This article aims to build a FAIR ML model pipeline using the generic FAIRification workflow to make the whole ML analytics process FAIR. Accordingly, FAIR input data was modelled using a FAIR ML model. The output data from the FAIR ML model was also made FAIR. For this, a hybrid hierarchical k-means (HHK) clustering ML algorithm was applied to group the data into homogeneous subgroups and ascertain the underlying structure of the data using a Nigerian-based FAIR dataset that contains data on economic factors, healthcare facilities, and coronavirus occurrences in all the 36 states of Nigeria. The model showed that research data and the ML pipeline can be FAIRified, shared, and reused by following the proposed FAIRification workflow and implementing technical architecture.</jats:p>",Workflow; Interoperability; Computer science; Pipeline (software); Usability; Analytics; Data model (GIS); Data mining; Data transformation; Data modeling; Database; Reuse; Data science; Artificial intelligence; World Wide Web; Engineering; Data warehouse; Human–computer interaction; Programming language; Waste management,,,10.1162/dint_a_00182,True,en,FAIRification of data
237,048-710-037-813-880,Clinical Research Informatics: Contributions from 2016.,2017,journal article,Yearbook of medical informatics,Georg Thieme Verlag KG,Germany,C. Daniel; R. Choquet,"Objectives: To summarize key contributions to current research in the field of Clinical Research Informatics (CRI) and to select the best papers published in 2016. Methods: A bibliographic search using a combination of MeSH and free terms on CRI was performed using PubMed, followed by a double-blind review in order to select a list of candidate best papers to be then peer-reviewed by external reviewers. A consensus meeting between the two section editors and the editorial team was organized to finally conclude on the selection of best papers. Results: Among the 452 papers published in 2016 in the various areas of CRI and returned by the query, the full review process selected four best papers. The authors of the first paper utilized a comprehensive representation of the patient medical record and semi-automatically labeled training sets to create phenotype models via a machine learning process. The second selected paper describes an open source tool chain securely connecting ResearchKit compatible applications (Apps) to the widely-used clinical research infrastructure Informatics for Integrating Biology and the Bedside (i2b2). The third selected paper describes the FAIR Guiding Principles for scientific data management and stewardship. The fourth selected paper focuses on the evaluation of the risk of privacy breaches in releasing genomics datasets. Conclusions: A major trend in the 2016 publications is the variety of research on “real-world data” – healthcare-generated data, person health data, and patient-reported outcomes - highlighting the opportunities provided by new machine learning techniques as well as new potential risks of privacy breaches.",Variety (cybernetics); Data management; Informatics; Data science; Guiding Principles; Stewardship; Field (computer science); Process (engineering); Data integration,,Biomedical Research; Clinical Trials as Topic; Confidentiality; Humans; Medical Informatics; Observational Studies as Topic,10.15265/iy-2017-024,True,en,Overview and Adoption of FAIR Principles
243,050-758-119-664-975,Recommendations for Improving the Quality of Rare Disease Registries.,2018,journal article,International journal of environmental research and public health,MDPI AG,Switzerland,Yllka Kodra; Jérôme Weinbach; Manuel Posada-de-la-Paz; Alessio Coi; S Lydie Lemonnier; David van Enckevort; Marco Roos; Annika Jacobsen; Ronald Cornet; S Faisal Ahmed; Virginie Bros-Facer; Veronica Popa; Marieke Van Meel; Daniel Renault; Rainald von Gizycki; Michele Santoro; Paul Landais; Paola Torreri; Claudio Carta; Deborah Mascalzoni; Sabina Gainotti; Estrella Lopez; Anna Ambrosini; Heimo Müller; Robert Reis; Fabrizio Bianchi; Yaffa R. Rubinstein; Hanns Lochmüller; Domenica Taruscio,"Rare diseases (RD) patient registries are powerful instruments that help develop clinical research, facilitate the planning of appropriate clinical trials, improve patient care, and support healthcare management. They constitute a key information system that supports the activities of European Reference Networks (ERNs) on rare diseases. A rapid proliferation of RD registries has occurred during the last years and there is a need to develop guidance for the minimum requirements, recommendations and standards necessary to maintain a high-quality registry. In response to these heterogeneities, in the framework of RD-Connect, a European platform connecting databases, registries, biobanks and clinical bioinformatics for rare disease research, we report on a list of recommendations, developed by a group of experts, including members of patient organizations, to be used as a framework for improving the quality of RD registries. This list includes aspects of governance, Findable, Accessible, Interoperable and Reusable (FAIR) data and information, infrastructure, documentation, training, and quality audit. The list is intended to be used by established as well as new RD registries. Further work includes the development of a toolkit to enable continuous assessment and improvement of their organizational and data quality.",Biobank; Health administration; Quality audit; Business; Health care; Information system; Data quality; Documentation; Knowledge management; Continuous assessment,patient registry; quality; rare diseases,Biomedical Research; Computational Biology; Data Accuracy; Europe; Humans; Information Storage and Retrieval/standards; Quality Improvement; Rare Diseases; Registries/standards,10.3390/ijerph15081644,True,en,Overview and Adoption of FAIR Principles
326,073-812-278-254-788,Applying the FAIR principles to data in a hospital: challenges and opportunities in a pandemic.,2022,journal article,Journal of biomedical semantics,Springer Science and Business Media LLC,United Kingdom,Núria Queralt-Rosinach; Rajaram Kaliyaperumal; César H Bernabé; Qinqin Long; Simone A Joosten; Henk Jan van der Wijk; Erik L A Flikkenschild; Kees Burger; Annika Jacobsen; Barend Mons; Marco Roos; null null; null null,"<AbstractText Label=""BACKGROUND"">The COVID-19 pandemic has challenged healthcare systems and research worldwide. Data is collected all over the world and needs to be integrated and made available to other researchers quickly. However, the various heterogeneous information systems that are used in hospitals can result in fragmentation of health data over multiple data 'silos' that are not interoperable for analysis. Consequently, clinical observations in hospitalised patients are not prepared to be reused efficiently and timely. There is a need to adapt the research data management in hospitals to make COVID-19 observational patient data machine actionable, i.e. more Findable, Accessible, Interoperable and Reusable (FAIR) for humans and machines. We therefore applied the FAIR principles in the hospital to make patient data more FAIR.</AbstractText>;           <AbstractText Label=""RESULTS"">In this paper, we present our FAIR approach to transform COVID-19 observational patient data collected in the hospital into machine actionable digital objects to answer medical doctors' research questions. With this objective, we conducted a coordinated FAIRification among stakeholders based on ontological models for data and metadata, and a FAIR based architecture that complements the existing data management. We applied FAIR Data Points for metadata exposure, turning investigational parameters into a FAIR dataset. We demonstrated that this dataset is machine actionable by means of three different computational activities: federated query of patient data along open existing knowledge sources across the world through the Semantic Web, implementing Web APIs for data query interoperability, and building applications on top of these FAIR patient data for FAIR data analytics in the hospital.</AbstractText>;           <AbstractText Label=""CONCLUSIONS"">Our work demonstrates that a FAIR research data management plan based on ontological models for data and metadata, open Science, Semantic Web technologies, and FAIR Data Points is providing data infrastructure in the hospital for machine actionable FAIR Digital Objects. This FAIR data is prepared to be reused for federated analysis, linkable to other FAIR data such as Linked Open Data, and reusable to develop software applications on top of them for hypothesis generation and knowledge discovery.</AbstractText>;           <CopyrightInformation>© 2022. The Author(s).</CopyrightInformation>",Interoperability; Metadata; Computer science; Analytics; Data science; Open data; Health care; Observational study; World Wide Web; Medicine; Economics; Economic growth; Pathology,FAIR; Hospital; Ontologies; Open science; Patient data; Research data management,COVID-19/epidemiology; Hospitals; Humans; Metadata; Pandemics; Semantic Web,10.1186/s13326-022-00263-7,True,en,FAIRification of data
347,081-393-517-949-816,From big data to better patient outcomes.,2022,journal article,Clinical chemistry and laboratory medicine,Walter de Gruyter GmbH,Germany,Tim Hulsen; David Friedecký; Harald Renz; Els Melis; Pieter Vermeersch; Pilar Fernandez-Calle,"Among medical specialties, laboratory medicine is the largest producer of structured data and must play a crucial role for the efficient and safe implementation of big data and artificial intelligence in healthcare. The area of personalized therapies and precision medicine has now arrived, with huge data sets not only used for experimental and research approaches, but also in the ""<i>real world</i>"". Analysis of real world data requires development of legal, procedural and technical infrastructure. The integration of all clinical data sets for any given patient is important and necessary in order to develop a patient-centered treatment approach. Data-driven research comes with its own challenges and solutions. The Findability, Accessibility, Interoperability, and Reusability (FAIR) Guiding Principles provide guidelines to make data findable, accessible, interoperable and reusable to the research community. Federated learning, standards and ontologies are useful to improve robustness of artificial intelligence algorithms working on big data and to increase trust in these algorithms. When dealing with big data, the univariate statistical approach changes to multivariate statistical methods significantly shifting the potential of big data. Combining multiple omics gives previously unsuspected information and provides understanding of scientific questions, an approach which is also called the systems biology approach. Big data and artificial intelligence also offer opportunities for laboratories and the <i>In Vitro</i> Diagnostic industry to optimize the productivity of the laboratory, the quality of laboratory results and ultimately patient outcomes, through tools such as predictive maintenance and ""moving average"" based on the aggregate of patient results.",,artificial intelligence; big data; data science; patient outcomes; personalized healthcare; precision medicine,Humans; Big Data; Artificial Intelligence; Algorithms; Delivery of Health Care; Precision Medicine/methods,10.1515/cclm-2022-1096,False,en,Overview and Adoption of FAIR Principles
369,089-669-875-130-785,The burden of Chronic Pelvic Pain (CPP): Costs and quality of life of women and men with CPP treated in outpatient referral centers.,2023,journal article,PloS one,Public Library of Science (PLoS),United States,David Hutton; Aida Mustafa; Soha Patil; Saira Rathod; Gautam Shrikhande; Arnold Advincula; Jessica Drummond; Peter Gregersen; Jason Hall; Christine Metz; Alexandra Milspaw; Iris Kerin Orbuch; Peter Stahl; Amy Stein; Allyson Shrikhande,"<AbstractText Label=""INTRODUCTION"">Chronic Pelvic Pain (CPP) is a complex, multifaceted condition that affects both women and men. There is limited literature on the cost utilization the healthcare system and CPP patients incur. The purpose of this analysis is to characterize the overall healthcare utilization, cost burden, and quality-of-life restrictions experienced by CPP patients using data from an outpatient pelvic rehabilitation practice.</AbstractText>;           <AbstractText Label=""METHODS"">Healthcare utilization data was gathered by systematically reviewing and analyzing data from new patient visit progress notes stored in the clinic's electronic health records (EHR). We obtained in-network costs by using the FAIR Health Consumer online database. Overall costs were then calculated as the utilization times the per-unit costs from the FAIR database. Additionally, data on patients' visual analogue scale (VAS), absenteeism, presenteeism emergency room visits, usage of common pain medications, use of diagnostics, and participation in common treatment modalities was gathered.</AbstractText>;           <AbstractText Label=""RESULTS"">Data from 607 patients was used. The overall cost burden per patient for all surgeries combined was $15,750 for in-network services. The cost burden for diagnostics was $5,264.22 and treatments was $8,937 per patient for in-network treatments.</AbstractText>;           <AbstractText Label=""CONCLUSION"">Chronic Pelvic Pain was found to have a large cost burden of $29,951 for in-network services which includes treatments, diagnostics, and surgeries. This analysis sets the stage for future investigations involving data on costs of medications that patients have tried prior to presenting to us and costs associated with work hours lost.</AbstractText>;           <CopyrightInformation>Copyright: © 2023 Hutton et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</CopyrightInformation>",Medicine; Referral; Health care; Presenteeism; Quality of life (healthcare); Absenteeism; Indirect costs; Cost driver; Medical emergency; Emergency medicine; Physical therapy; Family medicine; Nursing; Business; Management; Accounting; Marketing; Economics; Economic growth,,Male; Humans; Female; Quality of Life; Outpatients; Patient Acceptance of Health Care; Pain Measurement; Pelvic Pain/therapy; Chronic Pain/therapy,10.1371/journal.pone.0269828,True,en,Overview and Adoption of FAIR Principles
415,108-523-909-056-946,Applying FAIR Principles to Improve Data Searchability of Emergency Department Datasets: A Case Study for HCUP-SEDD,2020,journal article,Methods of information in medicine,Georg Thieme Verlag KG,Germany,Karishma Bhatia; James Tanch; Elizabeth S. Chen; Indra Neil Sarkar,"Background There is a recognized need to improve how scholarly data are managed and accessed. The scientific community has proposed the findable, accessible, interoperable, and reusable (FAIR) data principles to address this issue. Objective The objective of this case study was to develop a system for improving the FAIRness of Healthcare Cost and Utilization Project's State Emergency Department Databases (HCUP's SEDD) within the context of data catalog availability. Methods A search tool, EDCat (Emergency Department Catalog), was designed to improve the “FAIRness” of electronic health databases and tested on datasets from HCUP-SEDD. ElasticSearch was used as a database for EDCat's search engine. Datasets were curated and defined. Searchable data dictionary-related elements and unified medical language system (UMLS) concepts were included in the curated metadata. Functionality to standardize search terms using UMLS concepts was added to the user interface. Results The EDCat system improved the overall FAIRness of HCUP-SEDD by improving the findability of individual datasets and increasing the efficacy of searches for specific data elements and data types. Discussion The databases considered for this case study were limited in number as few data distributors make the data dictionaries of datasets available. The publication of data dictionaries should be encouraged through the FAIR principles, and further efforts should be made to improve the specificity and measurability of the FAIR principles. Conclusion In this case study, the distribution of datasets from HCUP-SEDD was made more FAIR through the development of a search tool, EDCat. EDCat will be evaluated and developed further to include datasets from other sources.",Data type; Findability; Interoperability; Information retrieval; Context (language use); Computer science; Unified Medical Language System; User interface; Metadata; Data dictionary,,"Databases, Factual; Emergency Service, Hospital; Health Information Interoperability; Health Services Accessibility; Information Storage and Retrieval; Metadata",10.1055/s-0040-1712510,False,en,Overview and Adoption of FAIR Principles
420,110-383-161-631-495,Preparing healthcare delivery organizations for managing computable knowledge.,2018,journal article,Learning health systems,Wiley,United States,Julia Adler-Milstein; Paige Nong; Charles P. Friedman,"Introduction The growth of data science has led to an explosion in new knowledge alongside various approaches to representing and sharing biomedical knowledge in computable form. These changes have not been matched by an understanding of what healthcare delivery organizations need to do to adapt and continuously deploy computable knowledge. It is therefore important to begin to conceptualize such changes in order to facilitate routine and systematic application of knowledge that improves the health of individuals and populations. Methods An AHRQ-funded conference convened a group of experts from a range of fields to analyze the current state of knowledge management in healthcare delivery organizations and describe how it needs to evolve to enable computable knowledge management. Presentations and discussions were recorded and analyzed by the author team to identify foundational concepts and new domains of healthcare delivery organization knowledge management capabilities. Results Three foundational concepts include 1) the current state of knowledge management in healthcare delivery organizations relies on an outdated biomedical library model, and only a small number of organizations have developed enterprise-scale knowledge management approaches that ""push"" knowledge in computable form to frontline decisions, 2) the concept of Learning Health Systems creates an imperative for scalable computable knowledge management approaches, and 3) the ability to represent data science discoveries in computable form that is FAIR (findable, accessible, interoperable, reusable) is fundamental to spread knowledge at scale. For healthcare delivery organizations to engage with computable knowledge management at scale, they will need new organizational capabilities across three domains: policies and processes, technology, and people. Examples of specific capabilities were developed. Conclusions Healthcare delivery organizations need to substantially scale up and retool their knowledge management approaches in order to benefit from computable biomedical knowledge.",Order (exchange); Interoperability; Scale (chemistry); Library model; Biomedical knowledge; Healthcare delivery; Computer science; Scalability; Concept learning; Knowledge management,healthcare delivery; knowledge management; organizational competencies,,10.1002/lrh2.10070,True,en,Overview and Adoption of FAIR Principles
434,117-836-362-655-518,Fast Healthcare Interoperability Resources (FHIR) in a FAIR Metadata Registry for COVID-19 Research.,2021,journal article,Studies in health technology and informatics,IOS Press,Netherlands,Sophie Anne Ines Klofenstein; Carina Nina Vorisek; Aliaksandra Shutsko; Moritz Lehne; Julian Sass; Matthias Löbe; Carsten Oliver Schmidt; Sylvia Thun,"Adopting international standards within health research communities can elevate data FAIRness and widen analysis possibilities. The purpose of this study was to evaluate the mapping feasibility against HL7® Fast Healthcare Interoperability Resources® (FHIR)® of a generic metadata schema (MDS) created for a central search hub gathering COVID-19 health research (studies, questionnaires, documents = MDS resource types). Mapping results were rated by calculating the percentage of FHIR coverage. Among 86 items to map, total mapping coverage was 94%: 50 (58%) of the items were available as standard resources in FHIR and 31 (36%) could be mapped using extensions. Five items (6%) could not be mapped to FHIR. Analyzing each MDS resource type, there was a total mapping coverage of 93% for studies and 95% for questionnaires and documents, with 61% of the MDS items available as standard resources in FHIR for studies, 57% for questionnaires and 52% for documents. Extensions in studies, questionnaires and documents were used in 32%, 38% and 43% of items, respectively. This work shows that FHIR can be used as a standardized format in registries for clinical, epidemiological and public health research. However, further adjustments to the initial MDS are recommended - and two additional items even needed when implementing FHIR. Developing a MDS based on the FHIR standard could be a future approach to reduce data ambiguity and foster interoperability.",Health care; Interoperability; Information retrieval; Metadata registry; Metadata schema; 2019-20 coronavirus outbreak; Coronavirus disease 2019 (COVID-19); Computer science; Resource (project management); Metadata; Data science; World Wide Web; Economics; Economic growth,COVID-19; FAIR data; Fast Healthcare Interoperability Resources; HL7 FHIR; Infrastructure; Metadata Standards; Syntactic Interoperability,COVID-19; Delivery of Health Care; Electronic Health Records; Health Level Seven; Humans; Metadata; Registries; SARS-CoV-2,10.3233/shti210817,True,en,Overview and Adoption of FAIR Principles
437,118-391-836-896-24X,The COVID - Curated and Open aNalysis aNd rEsearCh plaTform (CO-CONNECT).,2022,journal article,International Journal of Population Data Science,Swansea University,,Emily Jefferson; Aziz Sheik; Susan Hopkins; Philip Quinlan,"<jats:p>ObjectivesCO-CONNECT is making UK COVID-19 data Findable, Accessible, Interoperable and Reusable (FAIR) through a federated platform, which supports secure, anonymised research at scale and pace. This interdisciplinary project, spanning 22 organisations, is connecting data from &gt;50 large research cohorts and data collected through routine healthcare provision across the UK.; ApproachAcross the UK, data has been collected that can help us answer key questions about COVID-19. As the data are in many places with many different processes it is difficult and complex for public health groups, researchers, policymakers, and government to find and access lots of high-quality data quickly and efficiently to make decisions. In collaboration with Health Data Research UK, CO-CONNECT is streamlining processes of accessing data for research.; Results1) Discovering data and meta-analysis: CO-CONNECT enables researchers to determine how many people meet their research criteria within the various datasets across the UK through the Health Data Research Innovation Gateway Cohort Discovery tool e.g. “How many people in each dataset have had a PCR test which was positive and were under the age of 40?” Only summary level, anonymous data are provided so researchers can answer such questions rapidly without requiring multiple data governance permissions and directly contacting each data source. The tool also supports aggregate level meta-analysis of the data.; 2) Detailed analysis: With data governance approvals, researchers can analyse detailed level, standardised, linked, pseudonymised data in a Trusted Research Environment. The common format reduces the effort on each research project, supporting rapid research.; ConclusionProviding data in this de-identifiable, safe way enables rapid, robust research e.g., COVID-19 results from a test centre can be linked to hospital records along with prescriptions from pharmacies enabling researchers to understand whether people with different existing health conditions are more or less susceptible to COVID-19. If you want to know more visit https://co-connect.ac.uk.</jats:p>",Data governance; Interoperability; Data science; Government (linguistics); Computer science; Data quality; Data sharing; Gateway (web page); Open data; World Wide Web; Knowledge management; Business; Medicine; Metric (unit); Linguistics; Philosophy; Alternative medicine; Pathology; Marketing,,,10.23889/ijpds.v7i3.1792,True,en,Overview and Adoption of FAIR Principles
456,129-155-513-569-134,"Connecting data, tools and people across Europe: ELIXIR's response to the COVID-19 pandemic.",2020,journal article,European journal of human genetics : EJHG,Springer Science and Business Media LLC,United Kingdom,Niklas Blomberg; Katharina B Lauer,"ELIXIR, the European research infrastructure for life science data, provides open access to data, tools and workflows in the response to the COVID-19 pandemic. ELIXIR’s 23 nodes have reacted swiftly to support researchers in their combined efforts against the pandemic setting out three joint priorities: 1. Connecting national COVID-19 data platforms to create federated European COVID-19 Data Spaces; 2. Fostering good data management to make COVID-19 data open, FAIR and reusable over the long term; 3. Providing open tools, workflows and computational resources to drive reproducible and collaborative science. ELIXIR’s strategy is based on the support given by our national nodes - collectively spanning over 200 institutes - to research projects and on partnering with community initiatives to drive development and adoption of good data practice and community driven standards. ELIXIR Nodes provide support activities locally and internationally, from provisioning compute capabilities to helping collect viral sequence data from hospitals. Some Nodes have prioritised access to their national cloud and compute facilities for all COVID-19 research projects, while others have developed tools to search, access and share all data related to the pandemic in a national healthcare setting.",Elixir (programming language); Business; Health care; Data management; Provisioning; Workflow; Datasets as Topic; Data access; Knowledge management; Cloud computing,,"Betacoronavirus/genetics; Biomedical Research/organization & administration; COVID-19; Coronavirus Infections/epidemiology; Datasets as Topic; Europe/epidemiology; Humans; Information Dissemination/ethics; International Cooperation/legislation & jurisprudence; Pandemics; Pneumonia, Viral/epidemiology; Public Health/economics; SARS-CoV-2; Workflow",10.1038/s41431-020-0637-5,True,en,Infrastructure and Tools
457,129-707-096-074-642,The NHGRI-EBI GWAS Catalog: knowledgebase and deposition resource.,2022,journal article,Nucleic acids research,Oxford University Press (OUP),United Kingdom,Elliot Sollis; Abayomi Mosaku; Ala Abid; Annalisa Buniello; Maria Cerezo; Laurent Gil; Tudor Groza; Osman Güneş; Peggy Hall; James Hayhurst; Arwa Ibrahim; Yue Ji; Sajo John; Elizabeth Lewis; Jacqueline A L MacArthur; Aoife McMahon; David Osumi-Sutherland; Kalliope Panoutsopoulou; Zoë Pendlington; Santhi Ramachandran; Ray Stefancsik; Jonathan Stewart; Patricia Whetzel; Robert Wilson; Lucia Hindorff; Fiona Cunningham; Samuel A Lambert; Michael Inouye; Helen Parkinson; Laura W Harris,"The NHGRI-EBI GWAS Catalog (www.ebi.ac.uk/gwas) is a FAIR knowledgebase providing detailed, structured, standardised and interoperable genome-wide association study (GWAS) data to >200 000 users per year from academic research, healthcare and industry. The Catalog contains variant-trait associations and supporting metadata for >45 000 published GWAS across >5000 human traits, and >40 000 full P-value summary statistics datasets. Content is curated from publications or acquired via author submission of prepublication summary statistics through a new submission portal and validation tool. GWAS data volume has vastly increased in recent years. We have updated our software to meet this scaling challenge and to enable rapid release of submitted summary statistics. The scope of the repository has expanded to include additional data types of high interest to the community, including sequencing-based GWAS, gene-based analyses and copy number variation analyses. Community outreach has increased the number of shared datasets from under-represented traits, e.g. cancer, and we continue to contribute to awareness of the lack of population diversity in GWAS. Interoperability of the Catalog has been enhanced through links to other resources including the Polygenic Score Catalog and the International Mouse Phenotyping Consortium, refinements to GWAS trait annotation, and the development of a standard format for GWAS data.",Genome-wide association study; Interoperability; Metadata; Population; Biology; Data science; Computer science; Computational biology; World Wide Web; Genetics; Medicine; Single-nucleotide polymorphism; Environmental health; Gene; Genotype,,"Animals; Humans; Mice; DNA Copy Number Variations; Genome-Wide Association Study; National Human Genome Research Institute (U.S.); Phenotype; Polymorphism, Single Nucleotide; Software; United States; Knowledge Bases",10.1093/nar/gkac1010,True,en,Infrastructure and Tools
483,144-495-742-964-546,FAIRifying a Quality Registry Using OMOP CDM: Challenges and Solutions.,2022,journal article,Studies in health technology and informatics,IOS Press,Netherlands,Daniel Puttmann; Nicolette De Keizer; Ronald Cornet; Eric Van Der Zwan; Ferishta Bakhshi-Raiez,"The need for health data to be internationally Findable, Accessible, Interoperable and Reusable (FAIR) and thereby support integrative analysis with other datasets has become crystal clear in the ongoing pandemic. The Dutch National Intensive Care Evaluation (NICE) quality registry adopted the Observational Medical Outcomes Partnership Common Database Model (OMOP CDM) to achieve a FAIR database. In the process of adopting the OMOP CDM, many modeling, technical, and communication challenges needed to be solved. Through communication with the OMOP CDM implementation community, previously done research and trial-and-error we found solutions that we believe can help other healthcare institutions, especially ICU quality registries, FAIRify their databases.",Interoperability; Observational study; Quality (philosophy); General partnership; Computer science; Process (computing); Knowledge management; Process management; Data science; Business; World Wide Web; Medicine; Philosophy; Epistemology; Pathology; Finance; Operating system,ETL Process; OHDSI; OMOP CDM; Quality Registry,"Databases, Factual; Delivery of Health Care; Electronic Health Records; Pandemics; Registries",10.3233/shti220476,True,en,Overview and Adoption of FAIR Principles
505,159-652-333-148-442,FAIR Genomes metadata schema promoting Next Generation Sequencing data reuse in Dutch healthcare and research.,2022,journal article,Scientific data,Springer Science and Business Media LLC,United Kingdom,K Joeri van der Velde; Gurnoor Singh; Rajaram Kaliyaperumal; XiaoFeng Liao; Sander de Ridder; Susanne Rebers; Hindrik H D Kerstens; Fernanda de Andrade; Jeroen van Reeuwijk; Fini E De Gruyter; Saskia Hiltemann; Maarten Ligtvoet; Marjan M Weiss; Hanneke W M van Deutekom; Anne M L Jansen; Andrew P Stubbs; Lisenka E L M Vissers; Jeroen F J Laros; Esther van Enckevort; Daphne Stemkens; Peter A C 't Hoen; Jeroen A M Beliën; Mariëlle E van Gijn; Morris A Swertz,"The genomes of thousands of individuals are profiled within Dutch healthcare and research each year. However, this valuable genomic data, associated clinical data and consent are captured in different ways and stored across many systems and organizations. This makes it difficult to discover rare disease patients, reuse data for personalized medicine and establish research cohorts based on specific parameters. FAIR Genomes aims to enable NGS data reuse by developing metadata standards for the data descriptions needed to FAIRify genomic data while also addressing ELSI issues. We developed a semantic schema of essential data elements harmonized with international FAIR initiatives. The FAIR Genomes schema v1.1 contains 110 elements in 9 modules. It reuses common ontologies such as NCIT, DUO and EDAM, only introducing new terms when necessary. The schema is represented by a YAML file that can be transformed into templates for data entry software (EDC) and programmatic interfaces (JSON, RDF) to ease genomic data sharing in research and healthcare. The schema, documentation and MOLGENIS reference implementation are available at https://fairgenomes.org .",JSON; Metadata; Computer science; Documentation; Schema (genetic algorithms); RDF; Reuse; Data sharing; Software; World Wide Web; Data element; Data integration; Data science; Information retrieval; Semantic Web; Database; Biology; Medicine; Programming language; Ecology; Alternative medicine; Pathology,,Delivery of Health Care; Genomics; High-Throughput Nucleotide Sequencing; Humans; Metadata; Software,10.1038/s41597-022-01265-x,True,en,Infrastructure and Tools
515,165-233-719-118-175,Augmenting laboratory COVID serology data granularity for SARS-CoV-2 reporting.,2022,journal article,International Journal of Population Data Science,Swansea University,,Esmond Urwin; Andy Harris; Jenny Johnstone; Erum Masood; Antony Chuter; Michael Ferguson; Joanne Martin; Neil Sebire; Philip Quinlan; Emily Jefferson,"<jats:p>ObjectiveThe global COVID pandemic has highlighted the need for the reporting of enhanced serology data from laboratory testing data. Qualitative results alone do not provide detailed data to understand levels of SARS-CoV-2 seroprevalence within a populace. To enable this, a minimum data set is required to support standardised data reporting.&#x0D;; ApproachThe CO-CONNECT project is concerned with the response to COVID within the UK and how datasets can be made Findable, Accessible, Interoperable and Reusable (FAIR). One aspect of this is a focus upon improving granular levels of COVID serology testing data being reported by national laboratories to the National Pathology Exchange (NPEx). A study was conducted to ascertain the essential data elements that could formulate a COVID Serology Data Standard (CSDS). Three NHS laboratories acting as pilot studies and NPEx have been actively involved with the development of the CSDS, together with clinicians and academics from the CO-CONNECT project.&#x0D;; ResultsFeedback from clinicians, academics and NPEx has been collected, together with NHS laboratory feasibility analysis to derive a minimum set of data elements that form a proposed data standard to standardise the reporting of laboratory COVID serology data for the UK. The proposed CSDS comprises twelve data elements in total, grouped into four main areas, (1) subject identifier and test date and time, (2) analyser types, test kits and samples, (3) qualitative results and (4) quantitative results. To further support the standardisation effort, a proposed Health Level Seven (HL7) message structure has been created to enable the reporting of the CSDS data elements to NPEx.&#x0D;; ConclusionThe CSDS has been created to help augment levels of reported granular data for laboratory COVID serology testing. If adopted, this could enable healthcare professionals to better understand the calibration of assays across multiple analyser types and thus antibody response levels.</jats:p>",Computer science; Coronavirus disease 2019 (COVID-19); Interoperability; Analyser; Data set; Serology; Identifier; Data science; Snowball sampling; Test (biology); Pandemic; Set (abstract data type); Data mining; Medicine; Artificial intelligence; Pathology; World Wide Web; Disease; Immunology; Infectious disease (medical specialty); Paleontology; Chemistry; Chromatography; Antibody; Biology; Programming language,,,10.23889/ijpds.v7i3.1887,True,en,FAIRification of data
522,168-168-005-760-503,Data-Driven Approaches to Maximize the Impact of Pediatric Clinical Trials.,2022,journal article,Pediatrics,American Academy of Pediatrics (AAP),United States,Florence T Bourgeois,"In this issue of Pediatrics, Brewster et al1 present an analysis of pediatric clinical trials registered in ClinicalTrials.gov from 2007 to 2020. Focusing on interventional trials enrolling only children (up to 17 years), the authors examined rates of trial discontinuation and results reporting, including factors associated with these outcomes. Their analysis spans an extended period and encompasses a broad selection of trial designs and interventions, providing information on trends over time across the pediatric clinical trial enterprise. Their findings serve to highlight several key areas requiring continued focus and provide a benchmark for ongoing monitoring and assessment.The authors found that approximately 11% of trials were discontinued, with a modest reduction in this rate over the study period. Over one-third failed due to poor participant accrual, which was the most common reason for discontinuation irrespective of the type of trial sponsor. Prior studies have reported a wide range of rates for pediatric trial discontinuation and the current estimate is lower than previously reported. This is most likely related to the diverse types of trials examined in the current analysis, with prior evaluations focusing on more narrow trial selections, such as randomized pediatric clinical trials or pediatric drug trials conducted in the post-marketing phase.2,3 It is difficult to fully gauge the inefficiencies and loss this discontinuation rate represents without a better understanding of the resources invested in these trials or the number of participants enrolled in studies that failed to yield scientific findings. Nonetheless, it provides a reference across a broad cohort of pediatric trials and confirms the ongoing challenge of recruiting pediatric participants to clinical trials.The study also revealed that the timely dissemination of pediatric trial results through deposit in trial registries and publication in peer-reviewed journals, remains suboptimal. At 3 years since trial completion, only 23% of trials had results available in ClinicalTrials.gov and 39% had been published. Particularly notable is that compared with trials receiving funding from either industry or government entities, those sponsored by academic institutions were least likely to have results disseminated after trial completion (45% compared with 61% for trials with industry funding and 59% for those with government funding). This is consistent with prior studies demonstrating poor performance and marked variation in results reporting by academic medical centers across the US.4 While timely dissemination of research results represents a core mission of academic institutions, effective enforcement mechanisms are lacking. Closer monitoring of publication and reporting activities for pediatric clinical trials is warranted to reduce loss of scientific information and breaches in commitments to participating patients and families.5As we consider the persistent gap in generating clinical evidence and developing interventions for pediatric populations, we must consider not only ways to strengthen pediatric clinical trial infrastructure, but also methods to augment clinical trial data with other evidence types. Very few pediatric trials are large randomized controlled trials and the majority employ single-center designs.6 Leveraging collaborative networks and other multi-institutional endeavors should be the default approach whenever feasible to appropriately prioritize research questions, increase statistical power, and ensure study completion. Funding agencies can support ongoing development of such pediatric research infrastructure and encourage the use of multi-institutional study designs in research programs and funding opportunities. To supplement clinical trials, we must also maximize evidence generation from registries and real-world data, such as electronic heath records, pharmacy claims, and mobile technologies. Real-world data can be used in retrospective studies, for example by providing data for historical controls in the assessment of interventions used in small patient populations.7 These data can also support prospective, pragmatic randomized trials, where studies are embedded in routine clinical practice and longitudinal outcomes data are collected from electronic health records. Such studies hold tremendous promise in reducing costs and barriers to recruiting pediatric patients, enabling inclusion of diverse patient populations, and generating efficient and generalizable clinical evidence across pediatric healthcare settings.8The dissemination of trial results points to an additional area of consideration for maximizing the impact of pediatric clinical trials: data sharing and reuse. In clinical research, data sharing allows external investigators to augment and build on prior work by performing secondary analyses, meta-analyses of individual patient data, and method development. Since 2018, the International Committee of Medical Journal Editors (ICMJE) has required that a statement on plans for data sharing be included in publications of clinical trials, though the policy stopped short of making data sharing mandatory.9 The implementation of the current policy has been inconsistent, and it is estimated that less than a third of ICMJE-affiliated journals have adopted a data sharing policy.10 Beyond a commitment to share data, actual reuse of data requires additional resources and technical infrastructure, which may contribute to the low rates of data reuse seen in practice. Guiding principles have been established to facilitate sharing and effective data reuse, calling for all data to be FAIR: Findable, Accessible, Interoperable, and Reusable.11 Implementation of such a framework across pediatric clinical trials will require not only greater data transparency and incentivization in our research community, but also consistent use of standard pediatric terminologies and pediatric-specific data ontologies.To act on the findings reported by Brewster et al, we must build consensus across the pediatric clinical trial enterprise on key features and trial outcomes deemed essential to maximizing resources and advancing pediatric clinical care. These could include measures of trial discontinuation, results reporting, and data sharing and reuse. Using a standard set of metrics, a data-driven approach could be applied to monitoring activities and directing modification and strengthening of research infrastructures, governing policies, and investment strategies. Formalizing ongoing evaluation would provide the needed tools to efficiently advance pediatric clinical trial infrastructures and maximize benefits to child health.",Medicine; Intensive care medicine; Clinical trial; MEDLINE; Internal medicine; Political science; Law,,Child; Clinical Trials as Topic; Humans,10.1542/peds.2021-055815,False,en,Overview and Adoption of FAIR Principles
524,168-978-729-416-200,An enhanced version of the PHIRI infrastructure: improving the analytical services,2022,journal article,European Journal of Public Health,Oxford University Press (OUP),United Kingdom,F Estupiñán,"<jats:title>Abstract</jats:title>;                <jats:p>The PHIRI federated approach has consisted of the development of four research queries (use cases) mobilising individual data from a number of data hubs (nodes in the federation). Methodologically speaking, use cases have required the creation of specific cohorts of patients, population subgroups or populations, and the identification of events of interest - over-time differences in health status and care healthcare utilisation before and during the pandemic. Technologically speaking, PHIRI infrastructure consists of a distributed end-to-end analytical pipeline containing the statistical analysis workflow, including data quality assessment at origin and the mathematical algorithms. Once datasets are prepared in each data hub, partners run the analyses and produce a research output (dashboards containing the research results and tables with aggregated data) that is shared for results compilation and comparative analysis. An enhanced version of the PHIRI infrastructure should allow more complex data distribution. The research questions covered so far are aiming inference on populations or providers, which implies a very simple distribution methodology, as described. However, when the research questions requires inference on the individuals (eg, quasi-experimental study on the effectiveness of a real-life intervention), when the inference requires a hierarchical approach (ie, part of the variance is at individual level and part at cluster level) or when, several rounds of training are needed (eg, validation of an artificial intelligence) the approach would require sharing coefficients, distances in n-dimensional spaces or models, and, some times various rounds of distribution. Finally, an enhanced version of the PHIRI infrastructure should generalise the current FAIR approach limited to the publication of the analytical pipeline in ZENODO, setting up the services and tools required for an improved version of the PHIRI open-science strategy.</jats:p>",Computer science; Workflow; Inference; Pipeline (software); Data science; Statistical inference; Data mining; Population; Identification (biology); Health care; Variance (accounting); Artificial intelligence; Statistics; Medicine; Mathematics; Botany; Business; Environmental health; Accounting; Database; Economics; Biology; Programming language; Economic growth,,,10.1093/eurpub/ckac129.468,True,en,Infrastructure and Tools
534,173-687-288-029-950,Curriculum Development for FAIR Data Stewardship,2022,journal article,Data Intelligence,MIT Press,,Francisca Oladipo; Sakinat Folorunso; Ezekiel Ogundepo; Obinna Osigwe; Akinyinka Akindele,"<jats:title>Abstract</jats:title>;                <jats:p>The FAIR Guidelines attempts to make digital data Findable, Accessible, Interoperable, and Reusable (FAIR). To prepare FAIR data, a new data science discipline known as data stewardship is emerging and, as the FAIR Guidelines gain more acceptance, an increase in the demand for data stewards is expected. Consequently, there is a need to develop curricula to foster professional skills in data stewardship through effective knowledge communication. There have been a number of initiatives aimed at bridging the gap in FAIR data management training through both formal and informal programmes. This article describes the experience of developing a digital initiative for FAIR data management training under the Digital Innovations and Skills Hub (DISH) project. The FAIR Data Management course offers 6 short on-demand certificate modules over 12 weeks. The modules are divided into two sets: FAIR data and data science. The core subjects cover elementary topics in data science, regulatory frameworks, FAIR data management, intermediate to advanced topics in FAIR Data Point installation, and FAIR data in the management of healthcare and semantic data. Each week, participants are required to devote 7–8 hours of self-study to the modules, based on the resources provided. Once they have satisfied all requirements, students are certified as FAIR data scientists and qualified to serve as both FAIR data stewards and analysts. It is expected that in-depth and focused curricula development with diverse participants will build a core of FAIR data scientists for Data Competence Centres and encourage the rapid adoption of the FAIR Guidelines for research and development.</jats:p>",Stewardship (theology); Data management; Interoperability; Curriculum; Fair use; Knowledge management; Competence (human resources); Computer science; Business; World Wide Web; Political science; Sociology; Pedagogy; Management; Database; Politics; Law; Economics,,,10.1162/dint_a_00183,True,en,Overview and Adoption of FAIR Principles
